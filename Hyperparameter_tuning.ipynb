{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNq3MgoJyATNg5n3UfrFnap",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BearKS/Robotic-weed-control-system/blob/feature%2Fsegmentation/Hyperparameter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BH6Hq8gb2ErG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf \n",
        "import keras\n",
        "import segmentation_models as sm\n",
        "sm.set_framework('tf.keras')\n",
        "sm.framework()\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = 'predataset/'\n",
        "x_train_dir = os.path.join(DATA_DIR, 'train/images')\n",
        "y_train_dir = os.path.join(DATA_DIR, 'train/masks')\n",
        "\n",
        "x_valid_dir = os.path.join(DATA_DIR, 'val/images')\n",
        "y_valid_dir = os.path.join(DATA_DIR, 'val/masks')\n",
        "\n",
        "x_test_dir = os.path.join(DATA_DIR, 'test/images')\n",
        "y_test_dir = os.path.join(DATA_DIR, 'test/masks')"
      ],
      "metadata": {
        "id": "9fCy7ZWc3pkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = 128\n",
        "h = 128"
      ],
      "metadata": {
        "id": "HGCEYQm73tBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helper function for data visualization\n",
        "def visualize(**images):\n",
        "    \"\"\"PLot images in one row.\"\"\"\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "    \n",
        "# helper function for data visualization    \n",
        "def denormalize(x):\n",
        "    \"\"\"Scale image to range 0..1 for correct plot\"\"\"\n",
        "    x_max = np.percentile(x, 98)\n",
        "    x_min = np.percentile(x, 2)    \n",
        "    x = (x - x_min) / (x_max - x_min)\n",
        "    x = x.clip(0, 1)\n",
        "    return x\n",
        "    \n",
        "\n",
        "# classes for data loading and preprocessing\n",
        "class Dataset:\n",
        "    \"\"\"CamVid Dataset. Read images, apply augmentation and preprocessing transformations.\n",
        "    \n",
        "    Args:\n",
        "        images_dir (str): path to images folder\n",
        "        masks_dir (str): path to segmentation masks folder\n",
        "        class_values (list): values of classes to extract from segmentation mask\n",
        "        augmentation (albumentations.Compose): data transfromation pipeline \n",
        "            (e.g. flip, scale, etc.)\n",
        "        preprocessing (albumentations.Compose): data preprocessing \n",
        "            (e.g. noralization, shape manipulation, etc.)\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    CLASSES = ['plant']\n",
        "    \n",
        "    def __init__(\n",
        "            self, \n",
        "            images_dir, \n",
        "            masks_dir, \n",
        "            classes=None, \n",
        "            augmentation=None, \n",
        "            preprocessing=None,\n",
        "    ):\n",
        "        self.ids = os.listdir(images_dir)\n",
        "        self.images_fps = [os.path.join(images_dir, image_id) for image_id in self.ids]\n",
        "        self.masks_fps = [os.path.join(masks_dir, image_id) for image_id in self.ids]\n",
        "        \n",
        "        # convert str names to class values on masks\n",
        "        self.class_values = [self.CLASSES.index(cls.lower()) for cls in classes]\n",
        "        \n",
        "        self.augmentation = augmentation\n",
        "        self.preprocessing = preprocessing\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # read data\n",
        "        image = cv2.imread(self.images_fps[i])\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.imread(self.masks_fps[i], 0)\n",
        "        # mask = cv2.cvtColor(mask, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # extract certain classes from mask (e.g. cars)\n",
        "        masks = [(mask == v) for v in self.class_values]\n",
        "        mask = np.stack(masks, axis=-1).astype('float')\n",
        "        \n",
        "        # add background if mask is not binary\n",
        "        if mask.shape[-1] != 1:\n",
        "            background = 1 - mask.sum(axis=-1, keepdims=True)\n",
        "            mask = np.concatenate((mask, background), axis=-1)\n",
        "        \n",
        "        # apply augmentations\n",
        "        if self.augmentation:\n",
        "            sample = self.augmentation(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "        \n",
        "        # apply preprocessing\n",
        "        if self.preprocessing:\n",
        "            sample = self.preprocessing(image=image, mask=mask)\n",
        "            image, mask = sample['image'], sample['mask']\n",
        "            \n",
        "        return image, mask\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "    \n",
        "    \n",
        "class Dataloader(keras.utils.Sequence):\n",
        "    \"\"\"Load data from dataset and form batches\n",
        "    \n",
        "    Args:\n",
        "        dataset: instance of Dataset class for image loading and preprocessing.\n",
        "        batch_size: Integet number of images in batch.\n",
        "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(dataset))\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # collect batch data\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "        \n",
        "        # transpose list of lists\n",
        "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
        "        \n",
        "        return batch\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
        "        return len(self.indexes) // self.batch_size\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
        "        if self.shuffle:\n",
        "            self.indexes = np.random.permutation(self.indexes)   "
      ],
      "metadata": {
        "id": "JpJGQ4nu3xld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "def round_clip_0_1(x, **kwargs):\n",
        "    return x.round().clip(0, 1)\n",
        "\n",
        "# define heavy augmentations\n",
        "def get_training_augmentation():\n",
        "    train_transform = [\n",
        "\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "\n",
        "        A.ShiftScaleRotate(scale_limit=0.5, rotate_limit=0, shift_limit=0.1, p=1, border_mode=0),\n",
        "\n",
        "        A.PadIfNeeded(min_height=h, min_width=w, always_apply=True, border_mode=0),\n",
        "        # A.RandomCrop(height=h, width=w, always_apply=True),\n",
        "        A.CropNonEmptyMaskIfExists(height=h, width=w, always_apply=True,p = 1.0),\n",
        "\n",
        "        A.GaussNoise (p=0.2),\n",
        "        A.Perspective(p=0.5),\n",
        "\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.CLAHE(p=1),\n",
        "                A.RandomBrightness(p=1),\n",
        "                A.RandomGamma(p=1),\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.Sharpen(p=1),\n",
        "                A.Blur(blur_limit=3, p=1),\n",
        "                A.MotionBlur(blur_limit=3, p=1),\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "\n",
        "        A.OneOf(\n",
        "            [\n",
        "                A.RandomBrightnessContrast(p=1),\n",
        "                A.HueSaturationValue(p=1),\n",
        "            ],\n",
        "            p=0.9,\n",
        "        ),\n",
        "        # A.Lambda(mask=round_clip_0_1)\n",
        "    ]\n",
        "    return A.Compose(train_transform)\n",
        "\n",
        "\n",
        "def get_validation_augmentation():\n",
        "    \"\"\"Add paddings to make image shape divisible by 32\"\"\"\n",
        "    test_transform = [\n",
        "        A.PadIfNeeded(h, w)\n",
        "    ]\n",
        "    return A.Compose(test_transform)\n",
        "\n",
        "def get_preprocessing(preprocessing_fn):\n",
        "    \"\"\"Construct preprocessing transform\n",
        "    \n",
        "    Args:\n",
        "        preprocessing_fn (callbale): data normalization function \n",
        "            (can be specific for each pretrained neural network)\n",
        "    Return:\n",
        "        transform: albumentations.Compose\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    _transform = [\n",
        "        A.Lambda(image=preprocessing_fn),\n",
        "    ]\n",
        "    return A.Compose(_transform)"
      ],
      "metadata": {
        "id": "IOQw5Wok31sV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset for train images\n",
        "train_dataset = Dataset(\n",
        "    x_train_dir, \n",
        "    y_train_dir, \n",
        "    classes=CLASSES, \n",
        "    augmentation=get_training_augmentation(),\n",
        "    preprocessing=get_preprocessing(preprocess_input),\n",
        ")\n"
      ],
      "metadata": {
        "id": "a0xEZcW-4ANX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BACKBONE = 'vgg16'\n",
        "BATCH_SIZE = 8\n",
        "CLASSES = ['plant']\n",
        "LR = 0.0001\n",
        "EPOCHS = 40\n",
        "\n",
        "preprocess_input = sm.get_preprocessing(BACKBONE)"
      ],
      "metadata": {
        "id": "gh80_bzA3-vz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(lrn_rate,optimizer='Adam'):\n",
        "  n_classes = 1 if len(CLASSES) == 1 else (len(CLASSES) + 1)  # case for binary and multiclass segmentation\n",
        "  activation = 'sigmoid' if n_classes == 1 else 'softmax'\n",
        "\n",
        "  #create model\n",
        "  model = sm.Unet(BACKBONE, classes=n_classes, activation=activation)\n",
        "  if optimizer==\"Adam\":\n",
        "    opt = tf.keras.optimizers.Adam(lrn_rate)\n",
        "  elif optimizer==\"SGD\":\n",
        "    opt = keras.optimizers.SGD(learning_rate=lrn_rate)\n",
        "  else :\n",
        "    opt = keras.optimizers.Adadelta(learning_rate=lrn_rate) # need some default \n",
        "  # optim = tf.keras.optimizers.Adam(LR)\n",
        "\n",
        "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
        "  dice_loss = sm.losses.DiceLoss()\n",
        "  focal_loss = sm.losses.BinaryFocalLoss() if n_classes == 1 else sm.losses.CategoricalFocalLoss()\n",
        "  total_loss = dice_loss + (1 * focal_loss)\n",
        "\n",
        "  # actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
        "  # total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
        "\n",
        "  metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n",
        "\n",
        "  # compile keras model with defined optimozer, loss and metrics\n",
        "  model.compile(opt, total_loss, metrics)\n",
        "\n",
        "  return model;"
      ],
      "metadata": {
        "id": "HhsbZpO12Tf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "model = KerasRegressor(build_fn=create_model)"
      ],
      "metadata": {
        "id": "lqQo_V-o2jNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "for x,y in train_dataset:\n",
        "  x_train.append(x)\n",
        "  y_train.append(y)"
      ],
      "metadata": {
        "id": "lAeQSMfN2ptH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "Krrr4wKZ2sNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "OIsSRLLN4O1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the grid search parameters \n",
        "param_grid = dict(batch_size = batch_size, epochs=epochs,lrn_rate=learning_rate)\n",
        "# param_grid = dict(batch_size=batch_size, epochs=epochs,optimizer=optimizer,lrn_rate=learning_rate)\n",
        "# param_grid = dict( epochs=epochs,optimizer=optimizer,lrn_rate=learning_rate)\n",
        "#Grid Search Parameter: 4 x 3 x 3 = 36 combinations\n",
        "\n",
        "#Declare -> GridSearchCV()\n",
        "#run grid.fit() -> เก็บ accuracy ของ Cross validation (cv = 2)\n",
        "grid = GridSearchCV(estimator=model, n_jobs = 1, verbose= 0,cv=2, param_grid = param_grid, refit=True)\n",
        "print(x_train_dir,y_train_dir)\n",
        "grid_result = grid.fit(x_train,y_train)\n",
        "\n",
        "# estimator = grid_result.best_estimator_\n",
        "# estimator.model.save('my_model.h5')\n",
        "\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "print('Best params: ',grid_result.best_params_)\n",
        "print('Best score: ', grid_result.best_score_)\n",
        "\n",
        "\n",
        "# Display Statistics view\n",
        "# Error results from All combinations of grid parameters \n",
        "# -> plot() หรือ bar()\n",
        "# fig, (ax1, ax2) = plt.subplots(2, figsize=(20,10))\n",
        "# PlotBar(ax1,'Grid Search',means, params)\n",
        "# # PlotBar(ax2,'Random Search',means_2, params_2)\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "qbSfhbna21VO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}